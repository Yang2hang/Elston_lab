{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ac2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8071f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_h5_files(directory):\n",
    "    \"\"\"\n",
    "    Search for HDF5 files (.h5 extension) in the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory to search for HDF5 files.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of filenames (including paths) of HDF5 files found in the directory.\n",
    "    \"\"\"\n",
    "    h5_files = []\n",
    "    search_pattern = os.path.join(directory, '*.h5')  # Pattern to search for .h5 files\n",
    "\n",
    "    for file_path in glob.glob(search_pattern):\n",
    "        if os.path.isfile(file_path):\n",
    "            h5_files.append(file_path)\n",
    "\n",
    "    return h5_files\n",
    "\n",
    "def pull_from_h5(file_path, data_to_extract):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            # Check if the data_to_extract exists in the HDF5 file\n",
    "            if data_to_extract in file:\n",
    "                data = file[data_to_extract][...]  # Extract the data\n",
    "                return data\n",
    "            else:\n",
    "                print(f\"'{data_to_extract}' not found in the file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_neuron_profile(file_path):\n",
    "    \"\"\"\n",
    "    Extracts neuron tuning profiles from a single HDF5 session file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the .h5 file\n",
    "\n",
    "    Returns:\n",
    "    - neuron_profile: pd.DataFrame with tuning betas, p-values, and metadata\n",
    "    \"\"\"\n",
    "    # Load firing rates and metadata\n",
    "    fr_CdN = pull_from_h5(file_path, 'CdN_zFR')\n",
    "    fr_OFC = pull_from_h5(file_path, 'OFC_zFR')\n",
    "    firing_rates = np.concatenate([fr_CdN, fr_OFC], axis=2)\n",
    "\n",
    "    u_names = np.concatenate([pull_from_h5(file_path, 'CdN_u_names'),\n",
    "                              pull_from_h5(file_path, 'OFC_u_names')], axis=0)\n",
    "\n",
    "    n_CdN = fr_CdN.shape[2]\n",
    "    n_OFC = fr_OFC.shape[2]\n",
    "    brain_areas = np.concatenate([np.zeros(n_CdN), np.ones(n_OFC)]).astype(int)\n",
    "\n",
    "    u_locations = np.concatenate([pull_from_h5(file_path, 'CdN_locations'),\n",
    "                                  pull_from_h5(file_path, 'OFC_locations')], axis=0)\n",
    "\n",
    "    bhv = pd.read_hdf(file_path, key='bhv')\n",
    "    if len(bhv) > len(firing_rates):\n",
    "        bhv = bhv.iloc[:len(firing_rates)]\n",
    "\n",
    "    # Trial selection\n",
    "    trials2keep = bhv['n_sacc'] > 0\n",
    "    bhv = bhv.loc[trials2keep]\n",
    "    firing_rates = firing_rates[trials2keep, :, :]\n",
    "    firing_rates = np.nan_to_num(firing_rates, nan=0)\n",
    "\n",
    "    # Best-choice trials\n",
    "    mask = (bhv['n_sacc'] == 1) & (bhv['picked_best'] == 1)\n",
    "    trial_profile = bhv[mask].reset_index()\n",
    "    firing_single_best = firing_rates[mask.values, :, :]\n",
    "\n",
    "    mean_FR = firing_single_best.mean(axis=1)  # shape: (n_trials, n_units)\n",
    "    n_units = mean_FR.shape[1]\n",
    "\n",
    "    # GLM design matrix\n",
    "    df = pd.DataFrame({\n",
    "        'value': trial_profile['ch_val'].values,\n",
    "        'state': trial_profile['state'].values\n",
    "    })\n",
    "    state_dummies = pd.get_dummies(df['state'].astype(int), prefix='state')\n",
    "    df = pd.concat([df, state_dummies], axis=1)\n",
    "\n",
    "    df['state_value_1'] = df['value'] * df['state_1']\n",
    "    df['state_value_2'] = df['value'] * df['state_2']\n",
    "    df['state_value_3'] = df['value'] * df['state_3']\n",
    "\n",
    "    tuning_cols = ['value', 'state_1', 'state_2', 'state_3',\n",
    "                   'state_value_1', 'state_value_2', 'state_value_3']\n",
    "    X = df[tuning_cols].astype(int)\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit GLM for each neuron\n",
    "    beta_dict = {col: [] for col in X.columns}\n",
    "    pval_dict = {col: [] for col in X.columns}\n",
    "\n",
    "    for i in range(n_units):\n",
    "        y = mean_FR[:, i]\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        for col in X.columns:\n",
    "            beta_dict[col].append(model.params[col])\n",
    "            pval_dict[col].append(model.pvalues[col])\n",
    "\n",
    "    # Assemble neuron profile\n",
    "    neuron_profile = pd.DataFrame({\n",
    "        'neuron': u_names,\n",
    "        'brain_area': brain_areas,\n",
    "        'lateral': u_locations[:, 0],\n",
    "        'depth': u_locations[:, 1],\n",
    "        **{f'{col}_beta': beta_dict[col] for col in X.columns},\n",
    "        **{f'{col}_pval': pval_dict[col] for col in X.columns}\n",
    "    })\n",
    "\n",
    "    return neuron_profile\n",
    "\n",
    "def plot_neuron_centric_density(neuron_profile, tarkget_neurons=1, reference_filter=1, step_size=50, win_size=50):\n",
    "    \"\"\"\n",
    "    Plots neuron-centric density of value-coding neurons.\n",
    "\n",
    "    Parameters:\n",
    "    - neuron_profile (pd.DataFrame): DataFrame containing neuron profiles with 'coding_type', 'value_correlation', and 'depth' columns.\n",
    "    - tarkget_neurons (int): Target neuron type to analyze (1 for positive, -1 for negative).\n",
    "    - reference_filter (int): Reference neuron type to filter by (1 for positive, -1 for negative).\n",
    "    \"\"\"\n",
    "    target_property = {1: 'Positive', -1: 'Negative'}[tarkget_neurons]\n",
    "    reference_property = {1: 'Positive', -1: 'Negative'}[reference_filter]\n",
    "    u2plot = (neuron_profile['coding_type'] != 'none') & (neuron_profile['value_correlation'] == reference_filter)\n",
    "    u_betas = neuron_profile[u2plot]['value_correlation']\n",
    "    u_depths = neuron_profile[u2plot]['depth']\n",
    "\n",
    "    half_depth = (neuron_profile[u2plot]['depth'].max() - neuron_profile[u2plot]['depth'].min()) / 2\n",
    "    distances = np.arange(-half_depth, half_depth + 1, step_size)\n",
    "\n",
    "    all_u_centric_densities = []\n",
    "\n",
    "    for u in range(len(u_betas)):\n",
    "        center_depth = u_depths.iloc[u]\n",
    "\n",
    "        # Precompute masks for each window\n",
    "        window_masks = [(u_depths >= center_depth + d - win_size) & \n",
    "                        (u_depths < center_depth + d + win_size) \n",
    "                        for d in distances]\n",
    "        window_masks = np.stack(window_masks)  # shape: (num_windows, num_neurons)\n",
    "\n",
    "        tarkget_mask = (u_betas == tarkget_neurons).astype(float)  # shape: (num_neurons,)\n",
    "\n",
    "        # Compute densities for each neuron by applying window masks\n",
    "        # Resulting shape: (num_neurons, num_windows)\n",
    "        u_counts = window_masks.sum(axis=1)\n",
    "        u_centric_densities = (window_masks @ tarkget_mask) / np.maximum(u_counts, 1)  # avoid division by zero\n",
    "\n",
    "        all_u_centric_densities.append(u_centric_densities)\n",
    "        \n",
    "    all_u_centric_densities = np.array(all_u_centric_densities)\n",
    "    mean_density = all_u_centric_densities.mean(axis=0)\n",
    "\n",
    "    # Plot the density curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.lineplot(x=distances, y=mean_density, color='blue')\n",
    "    plt.axhline(0.5, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(f'Fraction of {target_property} Neurons Relative to {reference_property} Neurons. Step {step_size}, Win {win_size}')\n",
    "    plt.xlabel('Relative Depth (Î¼m)')\n",
    "    plt.ylabel(f'Fraction of {target_property} Neurons')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70920878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CdN_zFR' not found in the file.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m all_profiles \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m data_files:\n\u001b[1;32m----> 6\u001b[0m     profile \u001b[38;5;241m=\u001b[39m \u001b[43mextract_neuron_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     all_profiles\u001b[38;5;241m.\u001b[39mappend(profile)\n",
      "Cell \u001b[1;32mIn[11], line 47\u001b[0m, in \u001b[0;36mextract_neuron_profile\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m fr_CdN \u001b[38;5;241m=\u001b[39m pull_from_h5(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCdN_zFR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m fr_OFC \u001b[38;5;241m=\u001b[39m pull_from_h5(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOFC_zFR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m firing_rates \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfr_CdN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfr_OFC\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m u_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([pull_from_h5(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCdN_u_names\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     50\u001b[0m                           pull_from_h5(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOFC_u_names\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     52\u001b[0m n_CdN \u001b[38;5;241m=\u001b[39m fr_CdN\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "datadir = r\"D:\\Projects\\rotation_project\\reprocessed_data\"\n",
    "data_files = find_h5_files(datadir)\n",
    "\n",
    "all_profiles = []\n",
    "for file_path in data_files:\n",
    "    profile = extract_neuron_profile(file_path)\n",
    "    profile['session'] = file_path.split('\\\\')[-1].replace('.h5', '')\n",
    "    all_profiles.append(profile)\n",
    "\n",
    "combined_profile = pd.concat(all_profiles, ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elstonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
